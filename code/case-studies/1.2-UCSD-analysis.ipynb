{"cells":[{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\nimport qiime2 as q2\n\nfrom biom import Table\nfrom skbio import DistanceMatrix, OrdinationResults\nfrom qiime2.plugins.diversity.actions import beta, pcoa\nfrom skbio.stats.composition import closure\nfrom biom import load_table\nfrom gemelli.rpca import rpca, joint_rpca, rpca_table_processing\nfrom sklearn.model_selection import train_test_split\nnp.seterr(all=\"ignore\")"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["{'metaproteomics_cohort_two_matched': 108080 x 174 <class 'biom.table.Table'> with 5091405 nonzero entries (27% dense),\n"," 'metagenomics_cohort_two_matched': 3499 x 174 <class 'biom.table.Table'> with 163422 nonzero entries (26% dense),\n"," 'metabolomics_cohort_two_matched': 1928 x 174 <class 'biom.table.Table'> with 58524 nonzero entries (17% dense)}"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":"tables = {omics_.split('/')[-1].split('.')[0]:rpca_table_processing(load_table(omics_),\n                                                                    min_sample_count=0,\n                                                                    min_feature_count=0,\n                                                                    min_feature_frequency=0)\n          for omics_ in glob.glob('../../data/case-studies/uc-severity-multiomics/Cohort_two/*.biom')}\n\nmetadata = pd.read_csv('../../data/case-studies/uc-severity-multiomics/Cohort_two/metadata_cohort_two_revised.txt', sep='\\t', index_col=0)\ntables"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["metaproteomics_cohort_two_matched\n","metagenomics_cohort_two_matched\n","metabolomics_cohort_two_matched\n"]},{"data":{"text/plain":["dict_keys(['metaproteomics_cohort_two_matched', 'metagenomics_cohort_two_matched', 'metabolomics_cohort_two_matched'])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":"# make table/metadata pair for each dataset of all samples in the data\ntables_metdata_unshared = {}\nfor omics_, table_ in tables.items():\n    print(omics_)\n    metadata_omic = metadata.copy()\n    table_omic = table_.copy()\n    shared_samps = set(table_omic.ids()) & set(metadata.index)\n    table_omic = table_omic.filter(shared_samps)\n    table_omic = rpca_table_processing(table_omic, min_sample_count=0,\n                                       min_feature_count=0,\n                                       min_feature_frequency=0)\n    metadata_omic = metadata_omic.reindex(shared_samps)\n    table_omic_df = pd.DataFrame(table_omic.matrix_data.toarray(),\n                                 table_omic.ids('observation'),\n                                 table_omic.ids())\n    # these omics output in % abundance so have to use relative counts.\n    tables_metdata_unshared[omics_] = [table_omic, table_omic_df, metadata_omic]\n    \ntables_metdata_unshared.keys()\n"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["Diagnosis\n","IBD                157\n","Healthy_control     16\n","Name: count, dtype: int64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":"shared_samps = list(set.intersection(*[set(t_.ids()) for t_ in tables.values()]) & set(metadata.index))\nmetadata_shared = metadata.reindex(shared_samps)\nmetadata_shared['Diagnosis'] = [x.replace('UC','IBD').replace('CD','IBD')\n                                       for x in metadata_shared.Diagnosis]\n# re-close metaG/T data\nmetadata_shared = metadata_shared.reindex(shared_samps)\ntables_shared = {t_k:t_.copy().filter(shared_samps) for t_k, t_ in tables.items()}\n\n\"\"\"\nfor t_ in ['meta_g_taxonomic_profiles','meta_t_ecs']:\n    tbl_tmp = tables_shared[t_].to_dataframe().copy()\n    tbl_tmp = tbl_tmp.apply(closure)\n    tables_shared[t_] = Table(tbl_tmp.values, tbl_tmp.index, tbl_tmp.columns)\ntrain_, test_ = train_test_split(metadata_shared, shuffle=True,\n                                 stratify=metadata_shared['Diagnosis'],\n                                 test_size=0.25)\nmetadata_shared['train_test'] = 'train'\nmetadata_shared.loc[test_.index, 'train_test'] = 'test'\nmetadata_shared.to_csv('../../data/case-studies/uc-severity-multiomics/Cohort_two/sample-metadata-plus-train-tests-case-study.csv')\n\"\"\"\n\nmetadata_shared = pd.read_csv('../../data/case-studies/uc-severity-multiomics/Cohort_two/sample-metadata-plus-train-tests-case-study.csv', index_col=0)\nmetadata_shared.Diagnosis.value_counts()\n"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"from skbio.stats.composition import clr\nfrom sklearn.preprocessing import StandardScaler\n\nrerun = False\nif rerun:\n    scaler = StandardScaler(with_mean=False) # scale unit variance\n    transformations = {'metaproteomics_cohort_two_matched':clr,\n                       'metagenomics_cohort_two_matched':clr,\n                       'metabolomics_cohort_two_matched':clr}\n\n    tt_col = 'train_test'\n    train_ = metadata_shared[metadata_shared[tt_col] == 'train'].index\n    test_ = metadata_shared[metadata_shared[tt_col] == 'test'].index\n    for use_sub_, lbl_out_ in zip([train_, test_], ['train','test']):\n        stacked_clr_tables = {}\n        for t_, tbl_ in tables_shared.items():\n            df_ = pd.DataFrame(tbl_.matrix_data.toarray(),\n                               tbl_.ids('observation'), \n                               tbl_.ids()).loc[:, use_sub_]\n            data_ = df_.values\n            data_ = data_ + 1\n            data_ = clr(data_)\n            #data_ = scaler.fit_transform(clr(data_))\n            stacked_clr_tables[t_] = pd.DataFrame(data_, df_.index, df_.columns).stack().reset_index()\n        stacked_clr_tables = pd.concat(stacked_clr_tables)\n        stacked_clr_tables.columns = [\"feature\",\"sample\",\"value\"]\n        stacked_clr_tables = stacked_clr_tables.reset_index().drop(['level_1'], axis=1).rename({'level_0':'view'}, axis=1)\n        stacked_clr_tables = stacked_clr_tables[[\"sample\",\"feature\",\"value\",\"view\"]]\n        stacked_clr_tables['feature'] = stacked_clr_tables['view'] + '_' + stacked_clr_tables['feature']\n        # need to encode the feature names because MOFA does not like them\n        feat_map = {v:i for i, v in enumerate(set(stacked_clr_tables.feature))}\n        stacked_clr_tables['feature'] = [feat_map[v] for v in stacked_clr_tables['feature']]\n\n        #IMPORTANT: commenting-out due to space constraints\n        #stacked_clr_tables.to_csv('../../data/case-studies/uc-severity-multiomics/Cohort_two/mofa_tables/subset-%s.tsv.gz' % (lbl_out_), sep='\\t', compression='gzip')\n"},{"cell_type":"markdown","metadata":{},"source":"# RPCAs"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"if rerun:\n    for tbl_id, tbl_ in tables_shared.items():\n\n        for metric in ['braycurtis','aitchison']:\n            # produce train/test PCoA results on distances\n            tbl_q2 = q2.Artifact.import_data('FeatureTable[Frequency]', tbl_.copy())\n            q2dist_tmp = beta(tbl_q2, metric=metric).distance_matrix\n            dist_tmp = q2dist_tmp.view(DistanceMatrix)\n            ord_tmp = pcoa(q2dist_tmp).pcoa.view(OrdinationResults)\n            #IMPORTANT: commenting-out due to space constraints\n            #ord_tmp.write('../../data/case-studies/uc-severity-multiomics/Cohort_two/single-omics/%s-%s-ord.txt' % (tbl_id, metric))\n            #dist_tmp.write('../../data/case-studies/uc-severity-multiomics/Cohort_two/single-omics/%s-%s-dist.txt' % (tbl_id, metric))\n\n        metric = 'RPCA'\n        ord_tmp, dist_tmp = rpca(tbl_)\n        #ord_tmp.write('../../data/case-studies/uc-severity-multiomics/Cohort_two/single-omics/%s-%s-ord.txt' % (tbl_id, metric))\n        #dist_tmp.write('../../data/case-studies/uc-severity-multiomics/Cohort_two/single-omics/%s-%s-dist.txt' % (tbl_id, metric))\n"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/cameronmartino/Dropbox/bin/gemelli/gemelli/rpca.py:912: RuntimeWarning: Removing 0 features(s) in table(s) but not the ordination.\n","  warnings.warn('Removing %i features(s) in table(s)'\n"]}],"source":"# re-run with just the first train-test\n# (note: multiple folds did not results in much difference in ML classfiication in benchmarks)\nord_, dist_, cv_plt = joint_rpca([t.copy() for t in tables_shared.values()],\n                                 sample_metadata=metadata_shared,\n                                 train_test_column='train_test',\n                                 min_feature_frequency=10,\n                                 min_sample_count=0,\n                                 min_feature_count=0,\n                                 max_iterations=3)\nord_.write('../../data/case-studies/uc-severity-multiomics/Cohort_two/case-study-joint-rpca-ord.txt')\n#dist_.write('../../data/case-studies/uc-severity-multiomics/Cohort_two/case-study-joint-rpca-dist.txt')\n#cv_plt.to_csv('../../data/case-studies/uc-severity-multiomics/Cohort_two/case-study-joint-rpca-cv.txt')"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":4}