{"cells":[{"cell_type":"code","execution_count":null,"id":"68368852","metadata":{},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport tqdm\nimport mofax as mfx\nimport warnings\nimport random\n\nfrom skbio.stats.distance import permanova\nfrom gemelli.rpca import joint_rpca, rpca\nfrom helper_functions import simple_blocks\nfrom sklearn.model_selection import train_test_split\nfrom skbio.stats.composition import clr\nfrom biom import Table\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom skbio import DistanceMatrix\nfrom scipy.spatial import distance\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (average_precision_score, roc_auc_score)\nfrom tqdm.notebook import tqdm\n\n%matplotlib inline\nwarnings.filterwarnings('ignore', category=RuntimeWarning)"},{"cell_type":"markdown","id":"a76df04d","metadata":{},"source":"### Data simulation "},{"cell_type":"code","execution_count":null,"id":"d3139e94","metadata":{},"outputs":[],"source":"random.seed(42)\nn_samples = 50\ntables_save_joint = {}\nfeat_induced_dict = {}\nn_induced_lst = [5, 10, 20, 30, 40, 50, 60]\n\nfor n_induced in n_induced_lst:\n\n    feat_induced_lst = []\n    \n    for i_, n_features in enumerate([100, 150, 200]):\n\n        feat_signal_idx = random.sample(range(0, n_features), n_induced)\n        feat_ids = ['omic%s_f%i' % (i_+1, x) for x in feat_signal_idx]\n        feat_induced_lst.append(feat_ids)\n\n        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 6))\n        overlap_ = int(0.5*n_features) #ensure there's no underlying signal\n\n        # build simple three block model\n        np.random.seed(42)\n        bt_base_tmp, bt_sim_tmp, mf_sim_tmp = simple_blocks(n_samples, n_features, omic_id=\"omic%s\" %(i_+1),\n                                                            overlap=overlap_, n_blocks=2, percent_missing=2)\n        table_array = bt_sim_tmp.matrix_data.toarray().T\n        \n        #define cases from controls and features that get signal\n        controls_idx = np.arange(0, int(n_samples/2))     # first half are controls\n        signal_features = feat_signal_idx.copy()          # features that get signal\n\n        #sample from poisson dist\n        poisson_lambda = 1.0\n        poisson_signal = np.random.poisson(lam=poisson_lambda, size=(len(controls_idx), len(signal_features)))\n\n        # Add signal to selected samples/features\n        table_array[controls_idx[:, None], signal_features] += poisson_signal    \n        \n        #convert back to biom\n        table_biom = Table(table_array.T, \n                        bt_sim_tmp.ids('observation'), \n                        bt_sim_tmp.ids('sample'))\n\n        tables_save_joint[(\"fsignal_%s\" %n_induced, \"f_%i\" %n_features)] = table_biom.copy()\n        print(\"Done simulating data...\")\n\n    #save ids of the features with signal\n    feat_induced_dict[n_induced] = feat_induced_lst"},{"cell_type":"code","execution_count":null,"id":"db8e7d34","metadata":{},"outputs":[],"source":"#check densities\n#tables_save_joint"},{"cell_type":"code","execution_count":null,"id":"34d65f39","metadata":{},"outputs":[],"source":"# #save tables\n# #with open('../../data/simulations/lowrank/tables_three_microb_fsignal.pkl', 'wb') as file:\n# #    pickle.dump(tables_save_joint, file)\n\n# #save IDs of features with induced signal\n# with open('../../data/simulations/lowrank/microbs_with_signals.pkl', 'wb') as file:\n#     pickle.dump(feat_induced_dict, file)\n# #changes in v2: poisson signal and number of induced features"},{"cell_type":"code","execution_count":null,"id":"f16406f1","metadata":{},"outputs":[],"source":"#create train-test splits\n'''np.random.seed(42)\nmetadata = mf_sim_tmp.copy()\n\nfor f in range(10):\n    f += 1\n    train_, test_ = train_test_split(metadata, shuffle=True,\n                                     stratify=metadata['groups'],\n                                     test_size=0.25)\n    metadata['train_test_%i' % (f)] = 'train'\n    metadata.loc[test_.index, 'train_test_%i' % (f)] = 'test'\n\nsave metadata\nmetadata.to_csv('../../data/simulations/lowrank/metadata_diff_sparsities.csv')'''\n\n#load metadata\nmetadata = pd.read_csv('../../data/simulations/lowrank/metadata_diff_sparsities.csv', index_col=0)"},{"cell_type":"markdown","id":"270b879e","metadata":{},"source":"### MOFA+ Stacked Tables"},{"cell_type":"code","execution_count":9,"id":"779901e8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[('fsignal_60', 'f_100'), ('fsignal_60', 'f_150'), ('fsignal_60', 'f_200')], [('fsignal_50', 'f_100'), ('fsignal_50', 'f_150'), ('fsignal_50', 'f_200')], [('fsignal_40', 'f_100'), ('fsignal_40', 'f_150'), ('fsignal_40', 'f_200')], [('fsignal_30', 'f_100'), ('fsignal_30', 'f_150'), ('fsignal_30', 'f_200')], [('fsignal_20', 'f_100'), ('fsignal_20', 'f_150'), ('fsignal_20', 'f_200')], [('fsignal_10', 'f_100'), ('fsignal_10', 'f_150'), ('fsignal_10', 'f_200')], [('fsignal_5', 'f_100'), ('fsignal_5', 'f_150'), ('fsignal_5', 'f_200')], [('fsignal_2', 'f_100'), ('fsignal_2', 'f_150'), ('fsignal_2', 'f_200')]]\n","[60, 50, 40, 30, 20, 10, 5, 2]\n"]}],"source":"tables_joint = []\n\nfor n_induced in n_induced_lst:\n    tables_joint.append(\n        [(\"fsignal_%s\" %n_induced, 'f_100'), \n         (\"fsignal_%s\" %n_induced, 'f_150'), \n         (\"fsignal_%s\" %n_induced, 'f_200')])\n\ntables_joint = tables_joint[::-1]\nn_induced_idx = n_induced_lst[::-1]\nprint(tables_joint)\nprint(n_induced_idx)"},{"cell_type":"code","execution_count":null,"id":"dfb72e6c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[('fsignal_60', 'f_100'), ('fsignal_60', 'f_150'), ('fsignal_60', 'f_200')]\n","[('fsignal_50', 'f_100'), ('fsignal_50', 'f_150'), ('fsignal_50', 'f_200')]\n","[('fsignal_40', 'f_100'), ('fsignal_40', 'f_150'), ('fsignal_40', 'f_200')]\n","[('fsignal_30', 'f_100'), ('fsignal_30', 'f_150'), ('fsignal_30', 'f_200')]\n","[('fsignal_20', 'f_100'), ('fsignal_20', 'f_150'), ('fsignal_20', 'f_200')]\n","[('fsignal_10', 'f_100'), ('fsignal_10', 'f_150'), ('fsignal_10', 'f_200')]\n","[('fsignal_5', 'f_100'), ('fsignal_5', 'f_150'), ('fsignal_5', 'f_200')]\n","[('fsignal_2', 'f_100'), ('fsignal_2', 'f_150'), ('fsignal_2', 'f_200')]\n"]}],"source":"for idx, tables_ in enumerate(tables_joint):\n    print(tables_)\n    for f_ in range(10):\n        f_ += 1\n        tt_col = 'train_test_%i' % (f_)\n        train_ = metadata[metadata[tt_col] == 'train'].index\n        test_ = metadata[metadata[tt_col] == 'test'].index\n\n        for use_sub_, lbl_out_ in zip([train_, test_], ['train','test']):\n            stacked_clr_tables = {t_:pd.DataFrame(tables_save_joint[t_].matrix_data.toarray() + 0.1,\n                                                  tables_save_joint[t_].ids('observation'),\n                                                  tables_save_joint[t_].ids()).loc[:, use_sub_].apply(clr).stack().reset_index()\n                                  for t_ in tables_}\n            stacked_clr_tables = pd.concat(stacked_clr_tables)\n            stacked_clr_tables.columns = [\"feature\",\"sample\",\"value\"]\n            stacked_clr_tables = stacked_clr_tables.reset_index().drop(['level_0'], axis=1).rename({'level_1':'view'}, axis=1)\n            stacked_clr_tables = stacked_clr_tables[[\"sample\",\"feature\",\"value\",\"view\"]]\n            #stacked_clr_tables.to_csv('../../data/simulations/lowrank/mofa_tables_fsignal/fold-%i-subset-%s-fsignal%s.tsv.gz' % \n            #                         (f_, lbl_out_, n_induced_idx[idx]), sep='\\t', compression='gzip')"},{"cell_type":"markdown","id":"fe2ce8cd","metadata":{},"source":"### Joint-RPCA"},{"cell_type":"code","execution_count":null,"id":"1dd94e1e","metadata":{},"outputs":[],"source":"joint_ord_results = {}\n\nfor idx, tables_depth in enumerate(tables_joint):\n    print(tables_depth)\n    for f in range(10):\n        f += 1\n\n        #now, rerun Joint-RPCA with this number of iterations\n        ord_, _, cv_ = joint_rpca([tables_save_joint[joint_use_x].copy()\n                                    for joint_use_x in tables_depth],\n                                    max_iterations=50,\n                                    sample_metadata=metadata,\n                                    train_test_column='train_test_%i' % (f))\n        ord_plt = pd.concat([ord_.samples, metadata], axis=1)\n        joint_ord_results[n_induced_idx[idx], f] = (ord_plt, ord_.features, cv_)\n        display(ord_.features.sort_values(by='PC1', ascending=False).head(5))\n        display(ord_.features.sort_values(by='PC1', ascending=False).tail(5))\n\n        fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n        sns.scatterplot(x='PC1', y='PC2', hue='groups', s=60, data=ord_plt, ax=ax[0])\n        ax[0].set_title('Joint-RPCA: {}'.format(n_induced_idx[idx]), \n                        color='black', weight='bold', fontsize=18)\n        ax[0].set_ylabel('PC2', color='black', fontsize=15)\n        ax[0].set_xlabel('PC1', color='black', fontsize=15)\n        ax[0].set_facecolor('white')\n        ax[0].set_axisbelow(True)\n        sns.despine(ax=ax[0])\n\n        for child in ax[0].get_children():\n            if isinstance(child, matplotlib.spines.Spine):\n                child.set_color('black')\n        for tick in ax[0].get_xticklabels():\n            tick.set_fontproperties('arial')\n            tick.set_color(\"black\")\n            tick.set_weight(\"bold\")\n            tick.set_fontsize(12)\n        for tick in ax[0].get_yticklabels():\n            tick.set_fontproperties('arial')\n            tick.set_color(\"black\")\n            tick.set_weight(\"bold\")\n            tick.set_fontsize(12)"},{"cell_type":"code","execution_count":null,"id":"2e95ce67","metadata":{},"outputs":[],"source":"# with open('../../data/simulations/lowrank/joint-rpca_three_microb_fsignal.pkl', 'wb') as file:\n#   pickle.dump(joint_ord_results, file)"},{"cell_type":"markdown","source":"### Run all other methods with scripts 1.3-1.6","metadata":{}},{"cell_type":"markdown","id":"eef27cda","metadata":{},"source":"### MOFA+ Projections"},{"cell_type":"code","execution_count":null,"id":"01ebb3cb","metadata":{},"outputs":[],"source":"path_to_mofa = '../../data/simulations/lowrank/mofa_fsignal/'\nord_res_mofa = {}\nrename_cols = {'Factor1': 'PC1', 'Factor2': 'PC2', 'Factor3': 'PC3'}\n\nfor d in n_induced_idx:\n    #print(d)\n    for f in range(1,11):\n        # save ordination\n        df_ = pd.read_csv('%s%i.factors.model.fsignal%s.csv' % (path_to_mofa, f, d), index_col=0)\n        df_ = pd.pivot_table(columns='factor', values='value', index='sample', data=df_)\n        df_.rename(columns=rename_cols,inplace=True)\n        # center factors\n        df_ -= df_.mean()\n        df_ /= df_.std()\n\n        model = mfx.mofa_model(\"%s%i.model.fsignal%s.hdf5TRUE\" % (path_to_mofa, f, d))\n        test_data_project = pd.read_csv(\"../../data/simulations/lowrank/mofa_tables_fsignal/fold-%i-subset-test-fsignal%s.tsv.gz\" % (f, d), \n                                        index_col=0, sep='\\t', compression='gzip')\n        # project new data\n        # MOFAx projects on a single view, they vary greatly so we project on each one to be fair.\n        #print(model.views)\n        for view_use in model.views:\n            test_data_project_view = test_data_project[test_data_project.view == view_use]\n            test_data_project_view_X = pd.pivot_table(columns='sample',\n                                                      index='feature',\n                                                      values='value', data=test_data_project_view)\n            # ensure projection data is ordered the same as the input data\n            test_data_project_view_X = test_data_project_view_X.loc[[x for x in model.features[view_use]], :]\n            # project\n            new_values = np.stack([model.project_data(test_data_project_view_X.values.T, \n                                                      view=view_use, factors=i) for i in range(3)]).T\n            projected_factors = pd.DataFrame(new_values, test_data_project_view_X.columns, [['PC1','PC2','PC3']])\n            projected_factors.columns = ['PC1','PC2','PC3']\n            # center projections\n            projected_factors -= projected_factors.mean()\n            projected_factors /= projected_factors.std()\n            df_projected_ = pd.concat([df_, projected_factors], axis=0)\n            df_projected_.to_csv(\"%sprojections/fold-%i-fsignal%s-projected-on-fsignal%s.csv\"\n                                 % (path_to_mofa, f, d, view_use))\n            #add metdata and save\n            df_projected_ = pd.concat([df_projected_, metadata], axis=1)\n            ord_res_mofa[(d, f, view_use)] = df_projected_\n        # close model now that we are done\n        model.close()"},{"cell_type":"markdown","id":"2b5324ba","metadata":{},"source":"### RF Classification"},{"cell_type":"code","execution_count":44,"id":"9192fa18","metadata":{},"outputs":[],"source":"#load results (if coming back)\nwith open('../../data/simulations/lowrank/joint-rpca_three_microb_fsignal.pkl', 'rb') as file:\n   joint_ord_results = pickle.load(file)\n\n#load mofa results (with projections)\npath_to_mofa = '../../data/simulations/lowrank/mofa_fsignal/'\nord_res_mofa = {}\nn_induced_idx = [5, 10, 20, 30, 40, 50, 60]\n\nfor d in n_induced_idx:\n   for f in range(1,11):\n      for view_use in ['f_100', 'f_150', 'f_200']:\n         df_projected_ = pd.read_csv(\"%sprojections/fold-%i-fsignal%s-projected-on-fsignal%s.csv\"\n                                     % (path_to_mofa, f, d, view_use), index_col=0)\n         #add metdata and save\n         df_projected_ = pd.concat([df_projected_, metadata], axis=1)\n         ord_res_mofa[(d, f, view_use)] = df_projected_"},{"cell_type":"code","execution_count":34,"id":"75d874d4","metadata":{},"outputs":[],"source":"ord_res_mixomics = {}\n\nfor d in n_induced_idx:\n   for f in range(1,11):\n    df_ = pd.read_csv('../../data/simulations/lowrank/mixomics_fsignal/%s.factors.model.fsignal%s.csv'\n                      % (f, d), index_col=0)\n    \n    for view_use, view_df in df_.groupby('.id'):\n       view_df = view_df.set_index('subject')[['comp1','comp2','comp3']]\n       view_df.columns = ['PC1','PC2','PC3']\n       view_df = pd.concat([view_df, metadata], axis=1)\n       ord_res_mixomics[(d, f, view_use)] = view_df"},{"cell_type":"code","execution_count":35,"id":"ff11c48d","metadata":{},"outputs":[],"source":"ord_res_icluster = {}\n\nfor d in n_induced_idx:\n   for f in range(1,11):\n    # save ordination\n    view_df = pd.read_csv('../../data/simulations/lowrank/icluster_fsignal/%s.factors.model.fsignal%s.csv'\n                      % (f, d), index_col=0)\n    view_df.columns = ['PC1','PC2','PC3']\n    view_df = pd.concat([view_df, metadata], axis=1)\n    ord_res_icluster[(d, f)] = view_df"},{"cell_type":"code","execution_count":36,"id":"991d2778","metadata":{},"outputs":[],"source":"ord_res_intNMF = {}\n\nfor d in n_induced_idx:\n   for f in range(1,11):\n    # save ordination\n    view_df = pd.read_csv('../../data/simulations/lowrank/intNMF_fsignal/%s.factors.model.fsignal%s.csv'\n                      % (f, d), index_col=0)\n    view_df.columns = ['PC1','PC2','PC3']\n    view_df = pd.concat([view_df, metadata], axis=1)\n    ord_res_intNMF[(d, f)] = view_df"},{"cell_type":"code","execution_count":42,"id":"e9a78fd6","metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f7f00591f9374e22897e282e47a6fc75","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":"ord_res_all = {**{(k[0], k[1], 'Joint-RPCA'):v for k, v in joint_ord_results.items()},\n               **{(k[0], k[1], 'iCluster'):v for k, v in ord_res_icluster.items()},\n               **{(k[0], k[1], 'intNMF'):v for k, v in ord_res_intNMF.items()},}\n\npermanova_scores = {}\napr_scores = {}\nauc_roc_scores = {}\n\ncols_learn = ['PC1','PC2','PC3']\ncovert_map = {'g0': 1, 'g1': 0}\nclassifier = RandomForestClassifier(n_estimators=500, random_state=1010)\n\nfor fold in tqdm(range(10)):\n    fold += 1\n    # for all sparsity levels\n    for depth_ in n_induced_idx:\n        for metric_ in ['iCluster','intNMF','Joint-RPCA']:\n            # make a list to append for the dicts\n            if (depth_, metric_) not in permanova_scores.keys():\n                permanova_scores[(depth_, metric_)] = []\n                apr_scores[(depth_, metric_)] = []\n                auc_roc_scores[(depth_, metric_)] = []\n            \n            # get the ordination data\n            if metric_ == 'Joint-RPCA':\n                tbl = ord_res_all[(depth_, fold, metric_)][0].copy()\n            else:\n                tbl = ord_res_all[(depth_, fold, metric_)].copy()\n            tbl = tbl[cols_learn].dropna(subset=cols_learn)\n            # get labels\n            metadata_train = metadata[metadata['train_test_%i' % (fold)] == 'train']\n            metadata_test = metadata[metadata['train_test_%i' % (fold)] == 'test']\n            metadata_train = metadata_train.loc[list(set(tbl.index) & set(metadata_train.index)), :]\n            metadata_test = metadata_test.loc[list(set(tbl.index) & set(metadata_test.index)), :]\n            y_train = list(metadata_train['groups'].values)\n            y_train = [covert_map[i] for i in y_train]\n            y_test = list(metadata_test['groups'].values)\n            y_test = [covert_map[i] for i in y_test]\n            X_train = tbl.loc[metadata_train.index, :].values\n            X_test = tbl.loc[metadata_test.index, :].values\n            # permanova on test data (projection)\n            dist_tmp = DistanceMatrix(distance.cdist(tbl.loc[metadata_test.index, :], \n                                                    tbl.loc[metadata_test.index, :]), \n                                                    tbl.loc[metadata_test.index, :].index)\n            permanova_scores[(depth_, metric_)].append(\n                permanova(dist_tmp, metadata_test.loc[dist_tmp.ids, ['groups']].iloc[:, 0], permutations=1)['test statistic'])\n            # ML\n            scaler = StandardScaler()\n            X_train = scaler.fit_transform(X_train)\n            X_test = scaler.transform(X_test)\n            classifier.fit(X_train, y_train)\n            y_score = classifier.predict_proba(X_test)[:, 1]\n            y_pred = classifier.predict(X_test)\n            apr_scores[(depth_, metric_)].append(average_precision_score(y_test, y_score))\n            auc_roc_scores[(depth_, metric_)].append(roc_auc_score(y_test, y_score))"},{"cell_type":"code","execution_count":45,"id":"a98616fe","metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87c47d111f8641139b6c1b02e34feaac","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":"ord_res_all = {**{(k[0], k[1], k[2], 'MOFA'):v for k, v in ord_res_mofa.items()},\n               **{(k[0], k[1], k[2], 'mixOmics'):v for k, v in ord_res_mixomics.items()}}\n\npermanova_mofa = {}\napr_mofa = {}\nauc_mofa = {}\n\ncols_learn = ['PC1','PC2','PC3']\ncovert_map = {'g0': 1, 'g1': 0}\nclassifier = RandomForestClassifier(n_estimators=500, random_state=1010)\n\nfor fold in tqdm(range(10)):\n    fold += 1\n    #iterate through each depth\n    for depth_ in n_induced_idx:\n        for metric_ in ['MOFA', 'mixOmics']:\n            #and then each projection\n            for other_tbl_ in ['f_100', 'f_150', 'f_200']:\n                #print(fold, depth_, other_tbl_)\n                # make a list to append for the dicts\n                if (depth_, other_tbl_, metric_) not in permanova_mofa.keys():\n                    permanova_mofa[(depth_, other_tbl_, metric_)] = []\n                    apr_mofa[(depth_, other_tbl_, metric_)] = []\n                    auc_mofa[(depth_, other_tbl_, metric_)] = []\n                # get the ordination data\n                tbl = ord_res_all[(depth_, fold, other_tbl_, metric_)].copy()\n                # there might be iterations where only 2PCs were returned\n                tbl = tbl.dropna(axis=1)\n                cols_learn_ = [col for col in cols_learn if col in tbl.columns]\n                tbl = tbl[cols_learn_].dropna(subset=cols_learn_)\n                # get labels\n                metadata_train = metadata[metadata['train_test_%i' % (fold)] == 'train']\n                metadata_test = metadata[metadata['train_test_%i' % (fold)] == 'test']\n                metadata_train = metadata_train.loc[list(set(tbl.index) & set(metadata_train.index)), :]\n                metadata_test = metadata_test.loc[list(set(tbl.index) & set(metadata_test.index)), :]\n                y_train = list(metadata_train['groups'].values)\n                y_train = [covert_map[i] for i in y_train]\n                y_test = list(metadata_test['groups'].values)\n                y_test = [covert_map[i] for i in y_test]\n                X_train = tbl.loc[metadata_train.index, :].values\n                X_test = tbl.loc[metadata_test.index, :].values\n                # permanova on test data (projection)\n                dist_tmp = DistanceMatrix(distance.cdist(tbl.loc[metadata_test.index, :],\n                                                        tbl.loc[metadata_test.index, :]),\n                                                        tbl.loc[metadata_test.index, :].index)\n                permanova_mofa[(depth_, other_tbl_, metric_)].append(\n                    permanova(dist_tmp, metadata_test.loc[dist_tmp.ids, ['groups']].iloc[:, 0], permutations=1)['test statistic'])\n                # ML\n                scaler = StandardScaler()\n                X_train = scaler.fit_transform(X_train)\n                X_test = scaler.transform(X_test)\n                classifier.fit(X_train, y_train)\n                y_score = classifier.predict_proba(X_test)[:, 1]\n                y_pred = classifier.predict(X_test)\n                apr_mofa[(depth_, other_tbl_, metric_)].append(average_precision_score(y_test, y_score))\n                auc_mofa[(depth_, other_tbl_, metric_)].append(roc_auc_score(y_test, y_score))"},{"cell_type":"code","execution_count":null,"id":"3f7f2462","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["mixOmics      210\n","MOFA          210\n","iCluster       70\n","Joint-RPCA     70\n","intNMF         70\n","Name: method, dtype: int64\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ninduced</th>\n","      <th>method</th>\n","      <th>fold</th>\n","      <th>f_stat</th>\n","      <th>projection</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>0</td>\n","      <td>0.639686</td>\n","      <td>All</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>1</td>\n","      <td>0.814637</td>\n","      <td>All</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>2</td>\n","      <td>0.715067</td>\n","      <td>All</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>3</td>\n","      <td>0.453150</td>\n","      <td>All</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>4</td>\n","      <td>0.369297</td>\n","      <td>All</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ninduced    method  fold    f_stat projection\n","0         5  iCluster     0  0.639686        All\n","1         5  iCluster     1  0.814637        All\n","2         5  iCluster     2  0.715067        All\n","3         5  iCluster     3  0.453150        All\n","4         5  iCluster     4  0.369297        All"]},"metadata":{},"output_type":"display_data"}],"source":"#joint-rpca\njoint_permanova_all_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in permanova_scores.items() ])).T.stack().reset_index().dropna(axis=1)\njoint_permanova_all_df.columns = ['ninduced','method','fold','f_stat']\njoint_permanova_all_df['projection'] = 'All'\n#mofa\nmofa_permanova_all_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in permanova_mofa.items() ])).T.stack().reset_index().dropna(axis=1)\nmofa_permanova_all_df.columns = ['ninduced','projection','method','fold','f_stat']\nmofa_permanova_all_df = mofa_permanova_all_df[['ninduced','method','fold','f_stat','projection']]\n#append\npermanova_all_df = pd.concat([joint_permanova_all_df, mofa_permanova_all_df], axis=0)\nprint(permanova_all_df.method.value_counts())\npermanova_all_df.to_csv('../../data/simulations/lowrank/permanova-sample-level-fsignal-all.csv')\ndisplay(permanova_all_df.head())\n#display(permanova_all_df.tail())"},{"cell_type":"code","execution_count":58,"id":"80949f63","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["mixOmics      210\n","MOFA          210\n","iCluster       70\n","Joint-RPCA     70\n","intNMF         70\n","Name: method, dtype: int64\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ninduced</th>\n","      <th>method</th>\n","      <th>fold</th>\n","      <th>apr</th>\n","      <th>projection</th>\n","      <th>apr_error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>0</td>\n","      <td>0.661565</td>\n","      <td>All</td>\n","      <td>0.338435</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>1</td>\n","      <td>0.615843</td>\n","      <td>All</td>\n","      <td>0.384157</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>2</td>\n","      <td>0.538258</td>\n","      <td>All</td>\n","      <td>0.461742</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>3</td>\n","      <td>0.700168</td>\n","      <td>All</td>\n","      <td>0.299832</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>4</td>\n","      <td>0.805639</td>\n","      <td>All</td>\n","      <td>0.194361</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ninduced    method  fold       apr projection  apr_error\n","0         5  iCluster     0  0.661565        All   0.338435\n","1         5  iCluster     1  0.615843        All   0.384157\n","2         5  iCluster     2  0.538258        All   0.461742\n","3         5  iCluster     3  0.700168        All   0.299832\n","4         5  iCluster     4  0.805639        All   0.194361"]},"metadata":{},"output_type":"display_data"}],"source":"#joint-rpca\njoint_apr_all_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in apr_scores.items() ])).T.stack().reset_index().dropna(axis=1)\njoint_apr_all_df.columns = ['ninduced','method','fold','apr']\njoint_apr_all_df['projection'] = 'All'\n#mofa\nmofa_apr_all_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in apr_mofa.items() ])).T.stack().reset_index().dropna(axis=1)\nmofa_apr_all_df.columns = ['ninduced','projection','method','fold','apr']\nmofa_apr_all_df = mofa_apr_all_df[['ninduced','method','fold','apr','projection']]\n#append\napr_all_df = pd.concat([joint_apr_all_df, mofa_apr_all_df], axis=0)\napr_all_df['apr_error'] = 1 - apr_all_df.apr\nprint(apr_all_df.method.value_counts())\napr_all_df.to_csv('../../data/simulations/lowrank/apr-sample-level-fsignal-all.csv')\ndisplay(apr_all_df.head())\n#display(apr_all_df.tail())"},{"cell_type":"code","execution_count":59,"id":"80a67401","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["mixOmics      210\n","MOFA          210\n","iCluster       70\n","Joint-RPCA     70\n","intNMF         70\n","Name: method, dtype: int64\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ninduced</th>\n","      <th>method</th>\n","      <th>fold</th>\n","      <th>roc_auc</th>\n","      <th>projection</th>\n","      <th>roc_error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>0</td>\n","      <td>0.666667</td>\n","      <td>All</td>\n","      <td>0.333333</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>1</td>\n","      <td>0.476190</td>\n","      <td>All</td>\n","      <td>0.523810</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>2</td>\n","      <td>0.404762</td>\n","      <td>All</td>\n","      <td>0.595238</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>3</td>\n","      <td>0.654762</td>\n","      <td>All</td>\n","      <td>0.345238</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>iCluster</td>\n","      <td>4</td>\n","      <td>0.654762</td>\n","      <td>All</td>\n","      <td>0.345238</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ninduced    method  fold   roc_auc projection  roc_error\n","0         5  iCluster     0  0.666667        All   0.333333\n","1         5  iCluster     1  0.476190        All   0.523810\n","2         5  iCluster     2  0.404762        All   0.595238\n","3         5  iCluster     3  0.654762        All   0.345238\n","4         5  iCluster     4  0.654762        All   0.345238"]},"metadata":{},"output_type":"display_data"}],"source":"#joint-rpca\njoint_auc_all_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in auc_roc_scores.items() ])).T.stack().reset_index().dropna(axis=1)\njoint_auc_all_df.columns = ['ninduced','method','fold','roc_auc']\njoint_auc_all_df['projection'] = 'All'\n#mofa\nmofa_auc_all_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in auc_mofa.items() ])).T.stack().reset_index().dropna(axis=1)\nmofa_auc_all_df.columns = ['ninduced','projection','method','fold','roc_auc']\nmofa_auc_all_df = mofa_auc_all_df[['ninduced','method','fold','roc_auc','projection']]\n#append\nroc_all_df = pd.concat([joint_auc_all_df, mofa_auc_all_df], axis=0)\nroc_all_df['roc_error'] = 1 - roc_all_df.roc_auc\nprint(roc_all_df.method.value_counts())\nroc_all_df.to_csv('../../data/simulations/lowrank/roc-sample-level-fsignal-all.csv')\ndisplay(roc_all_df.head())\n#display(roc_all_df.tail())"},{"cell_type":"code","execution_count":null,"id":"24ecae3a","metadata":{},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"joint-rpca-benchmarking-flex","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":5}